import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as datasets
import torchvision.transforms as transforms #! load transformer
from torch.utils.data import DataLoader

# Define the CNN architecture
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)
        #! kernel_size: là window size (3,3). (3,3) is being called filler size. Filler using dot product to create output. 
        #! stride: số lần skip pixel
        #! padding: adding layer zero in the input (layer 0 bao bọc quanh input). Điều này để bảo toàn nó sẽ không thu nhỏ lại
        #! ví dụ: input 8x8 thì output cũng là 8x8
        #! input 3: nghĩa là 3 kênh RGB có thể xuất ra được 32 feature map. 
        #! For example, one feature map might represent the presence of edges, another might represent the presence of specific colors or textures, and so on
        self.relu = nn.ReLU() #! F(x) = max(0,x)
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) #! nghĩa là lấy max từ 2x2, có thể skip qua 2 phần tử nghĩa là stride về phía phải
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.flatten = nn.Flatten() #! reshape input into 1 dimensional vecto
        self.fc1 = nn.Linear(64 * 8 * 8, 64)
        self.fc2 = nn.Linear(64, 10)

    def forward(self, x):
        out = self.conv1(x)
        out = self.relu(out)
        out = self.maxpool(out)
        out = self.conv2(out)
        out = self.relu(out)
        out = self.maxpool(out)
        out = self.flatten(out)
        out = self.fc1(out)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
num_epochs = 1 #! Số lần model nhìn qua data
batch_size = 64 #! number of training example being process before update parameter
learning_rate = 0.001

# Load the CIFAR-10 dataset
train_dataset = datasets.CIFAR10(root='data/', train=True, transform=transforms.ToTensor(), download=True)
test_dataset = datasets.CIFAR10(root='data/', train=False, transform=transforms.ToTensor())

# Create data loaders
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# Initialize the CNN
model = CNN().to(device)

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate) #! update parameter during training
#! model.parameters() return a iterator of parameter of model = CNN().to(device)
# Train the model
total_step = len(train_loader)
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader): #! i: keep track in enumerate(0,(img1, label1))
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad() #! parameter to 0 to ensure thằng trước không dính líu tới thằng sau
        loss.backward() #! calculate derivative of the model.
        optimizer.step() #! update parameter

        if (i + 1) % 2 == 0: #! sau 100 lần thì là epoch 1 
            print(f'Epoch {epoch + 1}/{num_epochs}, Step {i + 1}/{total_step}, Loss: {loss.item()}')

# Test the model
model.eval()
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f'Test Accuracy: {accuracy}%')
